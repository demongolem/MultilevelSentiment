CiteULike Abstract
Bayesian l 0 â€�regularized least squares is a variable selection technique for highâ€�dimensional predictors. The challenge is optimizing a nonconvex objective function via search over model space consisting of all possible predictor combinations. Spikeâ€�andâ€�slab (aka Bernoulliâ€�Gaussian) priors are the gold standard for Bayesian variable selection, with a caveat of computational speed and scalability. Single best replacement (SBR) provides a fast scalable alternative. We provide a link between Bayesian regularization and proximal updating, which provides an equivalence between finding a posterior mode and a posterior mean with a different regularization prior. This allows us to use SBR to find the spikeâ€�andâ€�slab estimator. To illustrate our methodology, we provide simulation evidence and a real data example on the statistical properties and computational efficiency of SBR versus direct posterior sampling using spikeâ€�andâ€�slab priors. Finally, we conclude with directions for future research